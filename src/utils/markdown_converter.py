"""
Markdown è½‰æ›å™¨
å°‡ OCR çµæœè½‰æ›ç‚º Markdown æ ¼å¼
"""

import logging
import re
from typing import Dict, Any, List

logger = logging.getLogger(__name__)


class MarkdownConverter:
    """å°‡ OCR çµæœè½‰æ›ç‚º Markdown æ ¼å¼"""

    def _reorganize_paragraphs_with_figures(self, text: str) -> str:
        """
        é‡çµ„æ®µè½ï¼Œå°‡è¢«åœ–ç‰‡èªªæ˜ä¸­æ–·çš„æ®µè½é€£æ¥åœ¨ä¸€èµ·

        è™•ç†é‚è¼¯ï¼š
        1. æ‰¾åˆ°æ‰€æœ‰åœ–ç‰‡èªªæ˜æ¨™è¨˜
        2. æª¢æŸ¥åœ–ç‰‡èªªæ˜å‰å¾Œçš„æ–‡å­—æ˜¯å¦å±¬æ–¼åŒä¸€æ®µè½
        3. å¦‚æœæ˜¯ï¼Œå‰‡åˆä½µæ®µè½ï¼Œä¸¦å°‡åœ–ç‰‡èªªæ˜ç§»åˆ°æ®µè½å¾Œé¢

        Args:
            text: åŸå§‹ OCR æ–‡å­—

        Returns:
            é‡çµ„å¾Œçš„æ–‡å­—
        """
        # å…ˆç§»é™¤åˆ†é æ¨™è¨˜
        text = re.sub(
            r'\n*<---\s*Page\s*Split\s*--->\n*',
            ' ',
            text,
            flags=re.IGNORECASE
        )

        # æ‰¾åˆ°æ‰€æœ‰åœ–ç‰‡èªªæ˜åŠå…¶ä½ç½®
        figure_pattern = r'(<center>FIGURE[^<]+</center>)'

        # ä½¿ç”¨ split ä¿ç•™åˆ†éš”ç¬¦
        parts = re.split(figure_pattern, text)

        result_parts = []
        i = 0

        while i < len(parts):
            current_part = parts[i]

            # å¦‚æœç•¶å‰éƒ¨åˆ†æ˜¯åœ–ç‰‡èªªæ˜
            if re.match(figure_pattern, current_part):
                # æª¢æŸ¥å‰ä¸€å€‹éƒ¨åˆ†ï¼ˆæ–‡å­—ï¼‰å’Œå¾Œä¸€å€‹éƒ¨åˆ†ï¼ˆæ–‡å­—ï¼‰
                prev_text = result_parts[-1] if result_parts else ""
                next_text = parts[i + 1] if i + 1 < len(parts) else ""

                # åˆ¤æ–·æ˜¯å¦éœ€è¦åˆä½µæ®µè½
                should_merge = self._should_merge_paragraphs(
                    prev_text, next_text
                )

                if should_merge and result_parts and next_text:
                    # å¾çµæœä¸­ç§»é™¤å‰ä¸€å€‹æ–‡å­—éƒ¨åˆ†
                    prev_text = result_parts.pop()

                    # æ¸…ç†ä¸¦åˆä½µæ–‡å­—
                    prev_text = prev_text.rstrip()
                    next_text = next_text.lstrip()

                    # åˆä½µæ®µè½ï¼ˆåœ¨ä¸­é–“åŠ ä¸€å€‹ç©ºæ ¼ä»¥ç¢ºä¿å–®å­—ä¸æœƒé€£åœ¨ä¸€èµ·ï¼‰
                    merged_text = prev_text + ' ' + next_text

                    # æ·»åŠ åˆä½µå¾Œçš„æ®µè½
                    result_parts.append(merged_text)
                    # æ·»åŠ åœ–ç‰‡èªªæ˜
                    result_parts.append(current_part)

                    # è·³éä¸‹ä¸€å€‹éƒ¨åˆ†ï¼ˆå› ç‚ºå·²ç¶“åˆä½µäº†ï¼‰
                    i += 2
                else:
                    # ä¸éœ€è¦åˆä½µï¼Œç›´æ¥æ·»åŠ åœ–ç‰‡èªªæ˜
                    result_parts.append(current_part)
                    i += 1
            else:
                # æ™®é€šæ–‡å­—éƒ¨åˆ†ï¼Œåªæœ‰éç©ºæ™‚æ‰æ·»åŠ 
                if current_part or not result_parts:
                    result_parts.append(current_part)
                i += 1

        return ''.join(result_parts)

    def _should_merge_paragraphs(
        self, prev_text: str, next_text: str
    ) -> bool:
        """
        åˆ¤æ–·å…©å€‹æ–‡å­—ç‰‡æ®µæ˜¯å¦æ‡‰è©²åˆä½µç‚ºä¸€å€‹æ®µè½

        åˆ¤æ–·æ¨™æº–ï¼š
        1. å‰ä¸€æ®µæ–‡å­—ä¸æ˜¯ä»¥å¥è™Ÿã€å•è™Ÿã€é©šå˜†è™Ÿçµå°¾
        2. å¾Œä¸€æ®µæ–‡å­—ä»¥å°å¯«å­—æ¯æˆ–ã€Œandã€ç­‰é€£æ¥è©é–‹é ­
        3. å‰ä¸€æ®µæ–‡å­—ä¸æ˜¯ä»¥æ›è¡Œç¬¦çµå°¾ï¼ˆè¡¨ç¤ºä¸æ˜¯ç¨ç«‹æ®µè½ï¼‰

        Args:
            prev_text: å‰ä¸€æ®µæ–‡å­—
            next_text: å¾Œä¸€æ®µæ–‡å­—

        Returns:
            æ˜¯å¦æ‡‰è©²åˆä½µ
        """
        if not prev_text or not next_text:
            return False

        # æ¸…ç†ç©ºç™½å­—ç¬¦ä»¥ä¾¿æª¢æŸ¥
        prev_cleaned = prev_text.strip()
        next_cleaned = next_text.strip()

        if not prev_cleaned or not next_cleaned:
            return False

        # æª¢æŸ¥å‰ä¸€æ®µæ˜¯å¦ä»¥å¥å­çµæŸæ¨™é»ç¬¦è™Ÿçµå°¾
        sentence_endings = [
            '.', '?', '!', 'ã€‚', 'ï¼Ÿ', 'ï¼', ':', 'ï¼š'
        ]
        ends_with_punctuation = any(
            prev_cleaned.endswith(p) for p in sentence_endings
        )

        # æª¢æŸ¥å¾Œä¸€æ®µæ˜¯å¦ä»¥å°å¯«å­—æ¯æˆ–é€£æ¥è©é–‹é ­
        next_words = next_cleaned.split()
        next_first_word = next_words[0] if next_words else ""
        starts_with_lowercase = (
            next_first_word and next_first_word[0].islower()
        )

        # å¸¸è¦‹çš„é€£æ¥è©
        connecting_words = [
            'and', 'or', 'but', 'however', 'moreover', 'furthermore',
            'therefore', 'thus', 'hence', 'consequently', 'prompting',
            'resulting', 'leading', 'causing', 'which', 'that', 'who'
        ]
        starts_with_connector = (
            next_first_word.lower() in connecting_words
        )

        # å¦‚æœå‰ä¸€æ®µæ²’æœ‰ä»¥å¥è™Ÿçµå°¾ï¼Œä¸”å¾Œä¸€æ®µä»¥å°å¯«æˆ–é€£æ¥è©é–‹é ­ï¼Œ
        # å‰‡æ‡‰è©²åˆä½µ
        should_merge = (
            (not ends_with_punctuation) or
            starts_with_lowercase or
            starts_with_connector
        )

        return should_merge

    def _enhance_figure_markup(self, text: str) -> str:
        """
        å¢å¼·åœ–åƒæ¨™è¨˜ï¼Œä½¿å…¶åœ¨ Markdown ä¸­æ›´æ¸…æ¥š

        Args:
            text: åŸå§‹ OCR æ–‡å­—

        Returns:
            å¢å¼·å¾Œçš„æ–‡å­—
        """
        # é¦–å…ˆé‡çµ„æ®µè½ï¼Œå°‡è¢«åœ–ç‰‡èªªæ˜ä¸­æ–·çš„æ®µè½é€£æ¥åœ¨ä¸€èµ·
        text = self._reorganize_paragraphs_with_figures(text)

        # æ›¿æ› <center>FIGURE...</center> ç‚ºæ›´æ¸…æ¥šçš„ Markdown æ ¼å¼
        pattern = r'<center>(FIGURE [^<]+)</center>'

        def replace_figure(match):
            figure_text = match.group(1)
            # åˆ†é›¢æ¨™é¡Œå’Œèªªæ˜
            parts = figure_text.split('.', 1)
            if len(parts) == 2:
                title = parts[0].strip()
                description = parts[1].strip()
                return (
                    f"\n\n---\n\n### ğŸ“Š {title}\n\n"
                    f"**èªªæ˜**: {description}\n\n"
                    "> âš ï¸ *æ³¨æ„: æ­¤è™•ç‚ºåœ–åƒä½ç½®ã€‚OCR å·²æå–åœ–åƒä¸­çš„"
                    "æ–‡å­—æ¨™è¨»ï¼Œä½†ç„¡æ³•æä¾›åœ–åƒçš„è¦–è¦ºçµæ§‹æè¿°ã€‚*\n\n---\n\n"
                )
            else:
                return (
                    f"\n\n---\n\n### ğŸ“Š {figure_text}\n\n"
                    "> âš ï¸ *æ³¨æ„: æ­¤è™•ç‚ºåœ–åƒä½ç½®ã€‚*\n\n---\n\n"
                )

        text = re.sub(pattern, replace_figure, text, flags=re.DOTALL)

        # è™•ç†å…¶ä»–å¯èƒ½çš„åœ–åƒæ¨™è¨˜
        text = re.sub(
            r'<center>([^<]+)</center>',
            r'\n\n**\1**\n\n',
            text
        )

        return text

    def convert_to_markdown(self, ocr_result: Dict[str, Any]) -> str:
        """
        å°‡ OCR çµæœè½‰æ›ç‚º Markdown

        Args:
            ocr_result: AlphaXiv API è¿”å›çš„ OCR çµæœ

        Returns:
            Markdown æ ¼å¼çš„å­—ä¸²
        """
        logger.debug("é–‹å§‹è½‰æ› OCR çµæœç‚º Markdown")

        # æª¢æŸ¥çµæœæ ¼å¼
        if not ocr_result:
            logger.warning("OCR çµæœç‚ºç©º")
            return "# è™•ç†çµæœ\n\nç„¡æ³•å¾ PDF ä¸­æå–å…§å®¹ã€‚\n"

        markdown_lines = []

        # æ·»åŠ æ¨™é¡Œ
        markdown_lines.append("# OCR è™•ç†çµæœ\n")

        # è™•ç†ä¸åŒçš„å›æ‡‰æ ¼å¼
        # AlphaXiv æ ¼å¼: {"data": {"ocr_text": "..."}}
        if 'data' in ocr_result:
            data = ocr_result['data']
            if 'ocr_text' in data:
                markdown_lines.append("## æå–çš„æ–‡å­—å…§å®¹\n")
                # å¢å¼·åœ–åƒæ¨™è¨˜
                enhanced_text = self._enhance_figure_markup(data['ocr_text'])
                markdown_lines.append(enhanced_text)
                markdown_lines.append("\n")

                # æ·»åŠ çµ±è¨ˆä¿¡æ¯
                if 'num_pages' in data:
                    markdown_lines.append("\n---\n\n")
                    markdown_lines.append("## ğŸ“Š è™•ç†çµ±è¨ˆ\n\n")
                    markdown_lines.append(f"- **ç¸½é æ•¸**: {data['num_pages']}\n")
                    if 'num_successful' in data:
                        markdown_lines.append(
                            f"- **æˆåŠŸè™•ç†**: {data['num_successful']}\n"
                        )

                    # çµ±è¨ˆåœ–åƒæ•¸é‡
                    figure_count = len(
                        re.findall(r'<center>FIGURE', data['ocr_text'])
                    )
                    if figure_count > 0:
                        markdown_lines.append(
                            f"- **åœ–åƒæ•¸é‡**: {figure_count}\n"
                        )
                        tip = (
                            "\n> ğŸ’¡ **æç¤º**: OCR å·²æå–åœ–åƒä¸­çš„æ‰€æœ‰"
                            "æ–‡å­—æ¨™è¨»å’Œèªªæ˜ï¼Œä½†ç„¡æ³•æè¿°åœ–åƒçš„è¦–è¦ºå…§å®¹"
                            "ï¼ˆå¦‚æµç¨‹åœ–çµæ§‹ã€é—œä¿‚åœ–ç­‰ï¼‰ã€‚å¦‚éœ€åœ–åƒå…§å®¹"
                            "ç†è§£ï¼Œå»ºè­°ä½¿ç”¨ Vision Language Model "
                            "(å¦‚ GPT-4V)ã€‚\n"
                        )
                        markdown_lines.append(tip)

            elif 'text' in data:
                markdown_lines.append("## æå–çš„æ–‡å­—å…§å®¹\n")
                enhanced_text = self._enhance_figure_markup(data['text'])
                markdown_lines.append(enhanced_text)
                markdown_lines.append("\n")
            else:
                # data æ¬„ä½å­˜åœ¨ä½†æ ¼å¼ä¸ç¬¦ï¼Œé¡¯ç¤ºåŸå§‹å…§å®¹
                markdown_lines.append("## åŸå§‹çµæœ\n")
                markdown_lines.append("```json\n")
                import json
                markdown_lines.append(
                    json.dumps(data, ensure_ascii=False, indent=2)
                )
                markdown_lines.append("\n```\n")

        # æ ¼å¼1: ç›´æ¥åŒ…å« text æ¬„ä½
        elif 'text' in ocr_result:
            markdown_lines.append("## æå–çš„æ–‡å­—å…§å®¹\n")
            markdown_lines.append(ocr_result['text'])
            markdown_lines.append("\n")

        # æ ¼å¼2: åŒ…å« pages é™£åˆ—
        elif 'pages' in ocr_result:
            markdown_lines.append("## æ–‡ä»¶å…§å®¹\n")
            for page_num, page in enumerate(ocr_result['pages'], 1):
                markdown_lines.append(f"### ç¬¬ {page_num} é \n")
                if 'text' in page:
                    markdown_lines.append(page['text'])
                    markdown_lines.append("\n")

        # æ ¼å¼3: åŒ…å« content æ¬„ä½
        elif 'content' in ocr_result:
            markdown_lines.append("## æ–‡ä»¶å…§å®¹\n")
            markdown_lines.append(ocr_result['content'])
            markdown_lines.append("\n")

        # æ ¼å¼4: åŒ…å« results é™£åˆ—
        elif 'results' in ocr_result:
            markdown_lines.append("## è¾¨è­˜çµæœ\n")
            for item in ocr_result['results']:
                if isinstance(item, dict) and 'text' in item:
                    markdown_lines.append(item['text'])
                    markdown_lines.append("\n")
                elif isinstance(item, str):
                    markdown_lines.append(item)
                    markdown_lines.append("\n")

        # å¦‚æœéƒ½æ²’æœ‰ï¼Œå˜—è©¦å°‡æ•´å€‹çµæœè½‰ç‚ºå­—ä¸²
        else:
            markdown_lines.append("## åŸå§‹çµæœ\n")
            markdown_lines.append("```json\n")
            import json
            markdown_lines.append(
                json.dumps(ocr_result, ensure_ascii=False, indent=2)
            )
            markdown_lines.append("\n```\n")

        # æ·»åŠ å…ƒè³‡æ–™ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        if 'metadata' in ocr_result:
            markdown_lines.append("\n---\n")
            markdown_lines.append("## è™•ç†è³‡è¨Š\n")
            metadata = ocr_result['metadata']
            for key, value in metadata.items():
                markdown_lines.append(f"- **{key}**: {value}\n")

        result = '\n'.join(markdown_lines)
        logger.debug(f"Markdown è½‰æ›å®Œæˆï¼Œé•·åº¦: {len(result)} å­—å…ƒ")

        return result

    def format_text_blocks(self, text_blocks: List[Dict[str, Any]]) -> str:
        """
        æ ¼å¼åŒ–æ–‡å­—å€å¡Š

        Args:
            text_blocks: æ–‡å­—å€å¡Šåˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–çš„ Markdown å­—ä¸²
        """
        markdown_lines = []

        for block in text_blocks:
            block_type = block.get('type', 'text')

            if block_type == 'heading':
                level = block.get('level', 2)
                markdown_lines.append(
                    f"{'#' * level} {block.get('text', '')}\n"
                )

            elif block_type == 'paragraph':
                markdown_lines.append(f"{block.get('text', '')}\n")

            elif block_type == 'list':
                items = block.get('items', [])
                for item in items:
                    markdown_lines.append(f"- {item}\n")

            elif block_type == 'code':
                markdown_lines.append("```\n")
                markdown_lines.append(block.get('text', ''))
                markdown_lines.append("\n```\n")

            elif block_type == 'table':
                # ç°¡å–®çš„è¡¨æ ¼è™•ç†
                markdown_lines.append(self._format_table(block))

            else:
                markdown_lines.append(f"{block.get('text', '')}\n")

            markdown_lines.append("\n")

        return '\n'.join(markdown_lines)

    def _format_table(self, table_block: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–è¡¨æ ¼"""
        rows = table_block.get('rows', [])
        if not rows:
            return ""

        lines = []

        # æ¨™é¡Œè¡Œ
        if 'headers' in table_block:
            headers = table_block['headers']
            lines.append("| " + " | ".join(headers) + " |")
            lines.append("| " + " | ".join(["---"] * len(headers)) + " |")

        # è³‡æ–™è¡Œ
        for row in rows:
            if isinstance(row, list):
                row_text = " | ".join(str(cell) for cell in row)
                lines.append(f"| {row_text} |")

        return "\n".join(lines)
